{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2725da-51a9-4368-a56f-1512939ee3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer, TfidfVectorizer)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest, VarianceThreshold, f_classif)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, make_scorer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Custom\n",
    "from data_io import read_data\n",
    "from utils import label_map, normalize\n",
    "\n",
    "# BERT\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dce728-4735-4e1b-b904-030c1f050c18",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65ab210-e70b-4369-a040-52233af33070",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_train, labels_train = read_data(mode='train')\n",
    "y_train_full = np.asarray([label_map[label] for label in labels_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0597943-e880-4fbd-83ad-2ea6b877623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_val, labels_val = read_data(mode='val')\n",
    "y_val_full = np.asarray([label_map[label] for label in labels_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2eddc6-1411-4335-99f4-1fa317a4d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_test, labels_test = read_data(mode='test')\n",
    "y_test_full = np.asarray([label_map[label] for label in labels_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff45bc36-4ac6-4415-8663-efa90a83c14c",
   "metadata": {},
   "source": [
    "### BERT\n",
    "Load pretrained model from Tensorflow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07b9874-8f58-48bd-baf0-c39568f9121e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/google/experts/bert/pubmed/2\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'experts_pubmed' \n",
    "\n",
    "map_name_to_handle = {\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9731a0e-f0a2-4612-a5d3-ea60cf66b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeacaaa-4f2c-431a-b369-237e848d1137",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea30288b-84fc-4c64-980a-6b549abae933",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf10e988-57b7-49a8-8d00-217a4cd39fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = labelencoder.fit_transform(y_train_full)\n",
    "y_val_oh = labelencoder.fit_transform(y_val_full)\n",
    "y_test_oh = labelencoder.fit_transform(y_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a6495f0-df55-434b-87b1-a0ff337fbc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data (we use TF Hub BERT preprocessor)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(texts_train, dtype=tf.string), tf.convert_to_tensor(y_train_oh, dtype=tf.int32)))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(texts_val, dtype=tf.string), tf.convert_to_tensor(y_val_oh, dtype=tf.int32)))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((tf.convert_to_tensor(texts_test, dtype=tf.string), tf.convert_to_tensor(y_test_oh, dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb2f958-0c51-4636-b3d1-f7b684d8c22a",
   "metadata": {},
   "source": [
    "### Load and build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab1226f-a5d7-4cb6-ae45-50a8f2d4e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3da2ecfd-89eb-483d-b551-c263be25aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model(train_transformer=False):\n",
    "    \n",
    "    # Input Layer\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    \n",
    "    # Preprocessing with preprocessor\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    \n",
    "    # Pass through pretrained BERT model\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=train_transformer, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    \n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    net = tf.keras.layers.Dense(128)(net)\n",
    "    net = tf.keras.layers.Dense(128)(net)\n",
    "    net = tf.keras.layers.Dense(5, activation=\"softmax\", name='classifier')(net)\n",
    "    \n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6e8847-4f3f-48a5-857a-008dbe9aeebb",
   "metadata": {},
   "source": [
    "#### Load fine-tuned weights\n",
    "Please reach out to us, if you would like us to send you the fine-tuned weights of the tranformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b4dd3d-3315-4d07-80f7-41e69fe56e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model from TF Hub, then load the weights from the fine-tuning notebook.\n",
    "# Weights have been stored in the Weigths & Biases Cloud (https://wandb.ai)\n",
    "strategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"GPU:1\"])\n",
    "with strategy.scope():\n",
    "    \n",
    "    # Build and compile full model\n",
    "    embedding_model = build_classifier_model(True)\n",
    "    embedding_model.compile(\n",
    "        optimizer=\"Adam\",\n",
    "        loss=\"CategoricalCrossentropy\",\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Load fine-tuned weights\n",
    "    embedding_model.load_weights(\"./weights/bert_finetuned_1epoch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b17e2b-0c69-4279-af21-3d43287b5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model to check fine-tuned weights\n",
    "embedding_model.evaluate(val_ds.batch(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2cfc50-ca19-4b26-bcc1-b4382cfe2e66",
   "metadata": {},
   "source": [
    "#### Build new model to extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03fdf3ad-bbce-4dba-97fd-cb4f8f0c5a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "preprocessing (KerasLayer)      {'input_type_ids': ( 0           text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "BERT_encoder (KerasLayer)       {'pooled_output': (N 109482241   preprocessing[0][0]              \n",
      "                                                                 preprocessing[0][1]              \n",
      "                                                                 preprocessing[0][2]              \n",
      "==================================================================================================\n",
      "Total params: 109,482,241\n",
      "Trainable params: 109,482,240\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Builds a new model by detaching the classification head and only predicting the pooled output of the language model\n",
    "strategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"GPU:1\"])\n",
    "with strategy.scope():\n",
    "    model_embed = tf.keras.Model(inputs=embedding_model.input, outputs=embedding_model.get_layer(\"BERT_encoder\").output[\"pooled_output\"])\n",
    "\n",
    "model_embed.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57ddb0-d8e1-46c5-898f-310389cfa956",
   "metadata": {},
   "source": [
    "### Predict Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8fbde0c9-9e16-4d3e-a790-56542715dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_train = model_embed.predict(train_ds.batch(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "471d9f50-9c86-4d30-8a69-9a3fd893e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_val = model_embed.predict(val_ds.batch(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e9aa524-8133-4a1d-840a-6dd5cf71e994",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_test = model_embed.predict(test_ds.batch(128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae05088-7dbb-4c82-88aa-4158681e010d",
   "metadata": {},
   "source": [
    "### Store embeddings\n",
    "Please reach out to us, if you would like the predicted embeddings for accelerating the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "198c5587-3503-424e-a131-e7dd7dc74a41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\"./data/train_bert_finetuned_1epoch_embed_unnormalized_preprocessed\", embed_train, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c72b601-28e3-4f9f-9ad6-d4c3796f3d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/val_bert_finetuned_1epoch_embed_unnormalized_preprocessed\", embed_val, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b058a258-46f8-4c63-aa48-7d0249128f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/test_bert_finetuned_1epoch_embed_unnormalized_preprocessed\", embed_test, allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
