{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import nibabel as nib\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "\n",
    "# Load plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For parallel computations\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "import dask\n",
    "\n",
    "# Sklearn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.backend import int_shape\n",
    "from tensorflow.keras.layers import (\n",
    "    BatchNormalization, Conv2D, Conv2DTranspose,\n",
    "    MaxPooling2D, Dropout, Input, concatenate, Cropping2D\n",
    ")\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU support\n",
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device: \\\n",
    "    {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom Unet architecture\n",
    "from custom_unet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom metric functions\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom helper functions\n",
    "from utility import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "data_path = \"./data/ml4h_proj1_colon_cancer_ct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unpack data stored in given Google Drive Directory\n",
    "import tarfile\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "\n",
    "print(\"Downloading from Google Drive...\")\n",
    "gdd.download_file_from_google_drive(\n",
    "    file_id='', # data not publicly available\n",
    "    dest_path=data_path + \".tar.gz\",\n",
    "    showsize=True\n",
    ")\n",
    "\n",
    "print(\"Unpacking...\", end='')\n",
    "tar = tarfile.open(data_path + \".tar.gz\", \"r:gz\")\n",
    "tar.extractall(path=\"./data\")\n",
    "tar.close()\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T16:30:46.613345Z",
     "start_time": "2021-03-01T16:27:50.399252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load training data (images and labels) using helper function\n",
    "imgs, lbls = read_training_data_parallel(data_path, njobs=32, frac=None, load_scaled=True)\n",
    "print(len(imgs), len(lbls), imgs[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate some patients for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train, imgs_valid, lbls_train, lbls_valid = train_test_split(\n",
    "    imgs,\n",
    "    lbls,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "print(\"Number of training/validation patients\", len(imgs_train), len(imgs_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = read_testing_data_parallel(data_path, njobs=8, frac=None, load_scaled=True, get_names=True)\n",
    "print(len(test_data), test_data[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze depth distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different depth values:\n",
    "img_depths = set()\n",
    "for img in imgs_train:\n",
    "    img_depths.add(img.shape[2])\n",
    "\n",
    "print(\"Image depths: \", min(img_depths), \"to\", max(img_depths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_class = [1 if np.sum(lbl) > 0 else 0 for lbl in lbls_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Patients with cancerous tissue: {:.2f}%\".format(sum(imgs_class)/len(imgs_class) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancerous_layers = []\n",
    "for lbl in lbls:\n",
    "    cancerous_layers.append(len(get_cancerous_layers(lbl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(cancerous_layers)\n",
    "print(\"Mean number of cancerous layers:\", np.mean(cancerous_layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Split 3D images into separate layers considering two neighboring layers on each side for the input image and\n",
    "one neighbor on each side for the output segmentation mask. The model will thus learn a mapping from 5 channel 3D slices\n",
    "to 3 channel 3D slices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEIGHBORS = 2\n",
    "OUTPUT_NEIGHBORS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_sep = convert_depth_to_imgs_keras(imgs_train, neighbors=NEIGHBORS)\n",
    "valid_imgs_sep = convert_depth_to_imgs_keras(imgs_valid, neighbors=NEIGHBORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lbls_sep = convert_depth_to_imgs_keras(lbls_train, neighbors=OUTPUT_NEIGHBORS)\n",
    "valid_lbls_sep = convert_depth_to_imgs_keras(lbls_valid, neighbors=OUTPUT_NEIGHBORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze balance on converted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many samples actually contain cancerous tissue (balance check)\n",
    "count = sum([1 for l in train_lbls_sep if np.sum(l) > 0.0])\n",
    "print(\"Train ratio of images with canc. tissue {:.2f}% of {} images\".format(count/len(train_lbls_sep) * 100, len(train_lbls_sep)))\n",
    "\n",
    "count = sum([1 for l in valid_lbls_sep if np.sum(l) > 0.0])\n",
    "print(\"Valid ratio of images with canc. tissue {:.2f}% of {} images\".format(count/len(valid_lbls_sep) * 100, len(valid_lbls_sep)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsample\n",
    "Downsample the training and validation dataset to contain all layers with a cancerous\n",
    "segmentation result and a given ratio of images without a cancerous segmentation mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two different configurations have been used to train the two models of the ensemble\n",
    "\n",
    "# Configuration one (Model A and B in the report)\n",
    "# frac = 0.8\n",
    "# strategy = None\n",
    "\n",
    "# Configuration two (Model C in the report)\n",
    "frac = None\n",
    "strategy = {0: 500, 1: 950}\n",
    "\n",
    "imgs_down_train, lbls_down_train = downsample(train_imgs_sep, train_lbls_sep, frac=frac, strategy=strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a custom U-Net architecture\n",
    "Copied and adjusted from [Github: karolzak/keras-unet](https://github.com/karolzak/keras-unet)\n",
    "\n",
    "We refer to the naming adopted in our report. Three models are essential to the final results, all use the same network architecture with only slight modifications to the hyperparameters of the loss and the downsampling of the data, as well as the weight initialization\n",
    "- **Model A**\n",
    "    - Uses *random* weight initialization\n",
    "    - Trained with downsampled dataset of around 45% layers containing cancerous tissue\n",
    "    - Configures the loss with $\\beta=1.0$\n",
    "    - 100 epochs\n",
    "    - Achieves final validation 3D IoU of around ~0.15\n",
    "    - Named Model 5, when loading and saving\n",
    "- **Model B**\n",
    "    - Uses *pretrained* weight initialization\n",
    "    - Trained with downsampled dataset of around 45% layers containing cancerous tissue\n",
    "    - Configures the loss with $\\beta=1.0$\n",
    "    - 100 epochs\n",
    "    - Achieves final validation 3D IoU of around ~0.17\n",
    "    - Named Model 6, when loading and saving\n",
    "- **Model C**\n",
    "    - Uses *pretrained* weight initialization\n",
    "    - Trained with downsampled dataset of around 65% layers containing cancerous tissue\n",
    "    - Configures the loss with $\\beta=2.0$\n",
    "    - 80 epochs\n",
    "    - Achieves final validation 3D IoU of around ~0.16\n",
    "    - Named Model 7, when loading and saving\n",
    "- **Ensemble, Model D**\n",
    "    - Used for final predictions, averages predictions of Model B and C before thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "Use **Focal Tversky Loss** implementation from here: https://www.kaggle.com/bigironsphere/loss-function-library-keras-pytorch\n",
    "A combination of Focal Loss and Tversky Loss, which has been found to work well for a medical setting where the goal is \n",
    "to segment structures which are small and delicate compared to the overall image size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focal Tversky Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Keras\n",
    "ALPHA = 0.5 # Penalize False Positives\n",
    "BETA = 2.0  # Penalize False Negatives; two configurations have been used Beta=1.0 (Model A and B) and Beta=2.0 (Model C) for the respective models of the ensemble\n",
    "GAMMA = 4.0 # Focus on wrong predictions\n",
    "\n",
    "def FocalTverskyLoss(targets, inputs, alpha=ALPHA, beta=BETA, gamma=GAMMA, smooth=1e-6):\n",
    "    \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = K.flatten(targets)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = K.sum((inputs * targets))\n",
    "        FP = K.sum(((1-targets) * inputs))\n",
    "        FN = K.sum((targets * (1-inputs)))\n",
    "               \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        FocalTversky = K.pow((1 - Tversky), gamma)\n",
    "        \n",
    "        return FocalTversky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Validate on full patients (i.e. include all layers of each validation patient)\n",
    "# Load into contiguous memory\n",
    "valid_x = np.array(valid_imgs_sep, dtype=np.float32)\n",
    "valid_y = np.array(valid_lbls_sep, dtype=np.float32)\n",
    "\n",
    "# Save memory\n",
    "del valid_imgs_sep\n",
    "del valid_lbls_sep\n",
    "\n",
    "print(\"Validation data:\", len(valid_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation\n",
    "Apply transformations to the training data:\n",
    "\n",
    "- Random left/right flipping\n",
    "- Random up/down flipping\n",
    "- Random rotations\n",
    "- Add Gaussian Noise (Std=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformations(img, lbl):\n",
    "    \n",
    "    # Flip left-right randomly\n",
    "    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "    img = tf.cond(choice < 0.5, lambda: img, lambda: tf.image.flip_left_right(img))\n",
    "    lbl = tf.cond(choice < 0.5, lambda: lbl, lambda: tf.image.flip_left_right(lbl))\n",
    "    \n",
    "    # Flip up-down randomly\n",
    "    choice = tf.random.uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
    "    img = tf.cond(choice < 0.5, lambda: img, lambda: tf.image.flip_up_down(img))\n",
    "    lbl = tf.cond(choice < 0.5, lambda: lbl, lambda: tf.image.flip_up_down(lbl))\n",
    "    \n",
    "    # Rotate by random angle\n",
    "    angle = tf.random.uniform(shape=[], minval=0, maxval=360, dtype=tf.int32)\n",
    "    angle = tf.dtypes.cast(angle, tf.float32)\n",
    "    \n",
    "    img = tfa.image.rotate(img, angle)\n",
    "    lbl = tfa.image.rotate(lbl, angle)\n",
    "    \n",
    "    # Add noise to image\n",
    "    noise = tf.random.normal(shape=tf.shape(img), mean=1.0, stddev=0.05, dtype=tf.float32)\n",
    "    noise_img = tf.dtypes.cast(img, tf.float32) * noise\n",
    "    \n",
    "    return (noise_img, lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply transformations and prepare training data\n",
    "We double the training data and perturb each sample differently, then load into contiguous memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "for x, y in tqdm(zip(imgs_down_train, lbls_down_train), total=len(imgs_down_train)):\n",
    "    x_out, y_out = apply_transformations(x, y)\n",
    "    train_x.append(np.array(x_out))\n",
    "    train_y.append(np.array(y_out))\n",
    "    \n",
    "for x, y in tqdm(zip(imgs_down_train, lbls_down_train), total=len(imgs_down_train)):\n",
    "    x_out, y_out = apply_transformations(x, y)\n",
    "    train_x.append(np.array(x_out))\n",
    "    train_y.append(np.array(y_out))\n",
    "    \n",
    "train_x = np.array(train_x, dtype=np.float32)\n",
    "train_y = np.array(train_y, dtype=np.float32)\n",
    "\n",
    "# Save memory\n",
    "del imgs_down_train\n",
    "del lbls_down_train\n",
    "\n",
    "print(\"Training data:\", len(train_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Network, Loss and Metrics used (for model loading)\n",
    "custom_objects = {\n",
    "    'custom_unet' : custom_unet,\n",
    "    'FocalTverskyLoss': FocalTverskyLoss,\n",
    "    'iou_thresholded' : iou_thresholded,\n",
    "    'iou' : iou\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pretrained weights\n",
    "Weights have been pretrained on a dataset of CT scans with trachea segmentations\n",
    "\n",
    "- Model B and C both use the below pretrained network for weight initialization\n",
    "- Model A has been trained using random initialization of the network use the subsequent cell to randomly initialize the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"GPU:1\", \"GPU:2\", \"GPU:3\"])\n",
    "with strategy.scope():\n",
    "    unet = keras.models.load_model('./model/pretrained_transfer_trachea_1', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network loading\n",
    "**Careful** please do not execute the following cell, if you wish to train using the pretrained weights. It is only here for reference of the model layout. Executing it, will randomly initialize the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load network\n",
    "# strategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"GPU:1\", \"GPU:2\", \"GPU:3\"])\n",
    "# with strategy.scope():\n",
    "    \n",
    "#     unet = custom_unet(\n",
    "#         train_x[0].shape,\n",
    "#         num_classes=OUTPUT_NEIGHBORS * 2 + 1, # Number of output channels\n",
    "#         filters=64, # Number of filters in the first Conv. Block, doubled with each block\n",
    "#         use_batch_norm=True, # use batch normalization\n",
    "#         dropout=0.2,  # Use this amount of dropout\n",
    "#         dropout_change_per_layer=0.0, # Do not increase dropout on subsequent blocks\n",
    "#         dropout_type='spatial', # Use spatial dropout i.e. drop entire convolutional filters\n",
    "#         num_layers=4, # Number of Conv. Blocks, 4 is default for vanilla Unet\n",
    "#         upsample_mode='deconv', # Use transposed convolutions on upsampling part of network\n",
    "#         use_dropout_on_upsampling=False # No dropout in upsampling section\n",
    "#     )\n",
    "    \n",
    "#     unet.compile(\n",
    "#         optimizer=Adam(),\n",
    "#         loss=FocalTverskyLoss,\n",
    "#         metrics=[iou, iou_thresholded, tf.keras.metrics.AUC()]\n",
    "#     )\n",
    "    \n",
    "# unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store checkpoints for best validation loss model\n",
    "save_best_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    './model/best_checkpoint', monitor='val_loss', verbose=1, save_best_only=True,\n",
    "    save_weights_only=False, mode='min', save_freq='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Training\n",
    "- To train models A and B: 100 epochs have been run\n",
    "- To train model C: 80 epochs have been run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 80\n",
    "BATCH_SIZE = 24 # 128\n",
    "\n",
    "history = unet.fit(\n",
    "    train_x, train_y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    validation_data=(valid_x, valid_y),\n",
    "    callbacks=[PlotLossesKeras(), save_best_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Store model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NUMBER = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./model\", exist_ok=True)\n",
    "unet.save(f\"./model/promising_model_{MODEL_NUMBER}_transfer\", overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Fully Trained Models\n",
    "For ensembling Model B and C (corresponds to Model D) during prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model C (was model 7 in the development iteration process, thus the below naming)\n",
    "# strategy = tf.distribute.MirroredStrategy([\"GPU:0\", \"GPU:1\"])\n",
    "# with strategy.scope():\n",
    "#     unet7 = keras.models.load_model('./model/promising_model_7_transfer_80', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model B (was model 6 in the development iteration process, thus below naming)\n",
    "# strategy = tf.distribute.MirroredStrategy([\"GPU:2\", \"GPU:3\"])\n",
    "# with strategy.scope():\n",
    "#     unet6 = keras.models.load_model('./model/promising_model_6_transfer', custom_objects=custom_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and compute scores on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(samples, threshold=0.5):\n",
    "    \n",
    "    out = unet.predict(samples)\n",
    "    out = threshold_binarize(out, threshold=threshold)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subplots(plot_imgs, i, depth=0):\n",
    "    f, axarr = plt.subplots(1,8, figsize=(15,15))\n",
    "\n",
    "    axarr[0].imshow(plot_imgs[i][:,:,depth])\n",
    "    axarr[1].imshow(plot_imgs[i+1][:,:,depth])\n",
    "    axarr[2].imshow(plot_imgs[i+2][:,:,depth])\n",
    "    axarr[3].imshow(plot_imgs[i+3][:,:,depth])\n",
    "    axarr[4].imshow(plot_imgs[i+4][:,:,depth])\n",
    "    axarr[5].imshow(plot_imgs[i+5][:,:,depth])\n",
    "    axarr[6].imshow(plot_imgs[i+6][:,:,depth])\n",
    "    axarr[7].imshow(plot_imgs[i+7][:,:,depth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots_depth(img, depth=3, offset=0):\n",
    "    f, axarr = plt.subplots(1, depth, figsize=(15,15))\n",
    "    \n",
    "    for i in range(depth):\n",
    "        axarr[i].imshow(img[:,:,offset+i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze threshold response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_y = unet.predict(valid_x)\n",
    "# predict_tresh = threshold_binarize(predict_y, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def threshold_response_scores(valid_data, predict_data):\n",
    "#     thresholds = np.linspace(0.1, 1.0, 20)\n",
    "#     scores = []\n",
    "#     for t in tqdm(thresholds):\n",
    "#     #     score = iou_thresholded(valid_y, predict_y, threshold=t)\n",
    "#         score_f = lambda x: iou_thresholded(x[0], x[1], threshold=t)\n",
    "#         score = map(score_f, zip(valid_data, predict_data))\n",
    "#         score = np.mean(list(score))\n",
    "#         scores.append(float(score))\n",
    "        \n",
    "#     return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = threshold_response_scores(valid_y, predict_y)\n",
    "# thresholds = np.linspace(0.1, 1.0, 20)\n",
    "# ax = sns.lineplot(x=tresholds, y=scores)\n",
    "# ax = ax.set(xlabel='Treshold', ylabel='IoU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, tpr, tresh_roc = roc_curve(valid_y.ravel(), predict_y.ravel())\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print(\"AuROC: {"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(x=fpr[0::1000], y=tpr[0::1000])\n",
    "# ax = ax.set(xla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_subplots(valid_y, INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_subplots(predict_y, INDEX)\n",
    "# make_subplots(predict_y_checkpoint, INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_subplots(predict_tresh, INDEX)\n",
    "# make_subplots(predict_tresh_checkpoint, INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute 3d IoU over validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clamping function\n",
    "def clamp(n, minn, maxn):\n",
    "    return max(min(maxn, n), minn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for a single patient using a given network\n",
    "# For each layer we overlap and average the predictions\n",
    "# for the same layer due to the 3 channel output of the model\n",
    "def predict_patient_averaged(img, net, threshold=0.5):\n",
    "    \n",
    "    sep = convert_depth_to_imgs_keras([img], neighbors=NEIGHBORS, print_shape=False)\n",
    "    pred = net.predict(np.array(sep, dtype=np.float32))\n",
    "    \n",
    "    # Compute a single averaged layer considering the outputs\n",
    "    # of the neighboring layer predictions and channels\n",
    "    def compute_averaged_layer(predictions, i_layer):\n",
    "        \n",
    "        tmp = []\n",
    "        for j in range(-OUTPUT_NEIGHBORS, OUTPUT_NEIGHBORS+1):\n",
    "            \n",
    "            layer = i_layer + j\n",
    "            channel = j * -1 + OUTPUT_NEIGHBORS\n",
    "            if i_layer == 0 and layer < 0:\n",
    "                channel = OUTPUT_NEIGHBORS\n",
    "            if i_layer == predictions.shape[0]-1 and layer >= predictions.shape[0]:\n",
    "                channel = OUTPUT_NEIGHBORS\n",
    "            \n",
    "            layer = clamp(layer, 0, predictions.shape[0]-1)\n",
    "            tmp.append(predictions[layer][:,:,channel])\n",
    "            \n",
    "            \n",
    "        tmp = np.array(tmp, dtype=np.float32)\n",
    "        return np.mean(tmp, axis=0)\n",
    "        \n",
    "    \n",
    "    out = []\n",
    "    # Compute the averaged layer for each layer for given patient\n",
    "    for i in range(pred.shape[0]):       \n",
    "        layer_avg = dask.delayed(compute_averaged_layer)(pred, i)\n",
    "        out.append(layer_avg)\n",
    "    \n",
    "    out = dask.compute(*out, num_workers=24)\n",
    "    \n",
    "    output = np.moveaxis(np.array(out, dtype=np.float32), 0, -1)  \n",
    "        \n",
    "    return output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the 3D IoU given a patient and its labels\n",
    "def compute_3d_IoU(img, val, threshold=0.5):\n",
    "    \n",
    "    pred = predict_patient_averaged(img, unet, threshold=threshold)\n",
    "    \n",
    "    smooth=1.\n",
    "    y_true_f = K.flatten(np.array(val, dtype=np.float32))\n",
    "    y_pred_f = K.flatten(pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)\n",
    "    \n",
    "    return float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute validation 3D IoU score using the ensemble of models\n",
    "def compute_validation_3dscore(t):\n",
    "    scores = []\n",
    "    for img, val, i in tqdm(zip(imgs_valid, lbls_valid, range(len(imgs_valid))), total=len(imgs_valid)):\n",
    "\n",
    "        # Predict with both models B and C for ensembling into Model D\n",
    "        pred6 = predict_patient_averaged(img, unet6, threshold=t) # Model B\n",
    "        pred7 = predict_patient_averaged(img, unet7, threshold=t) # Model C\n",
    "        \n",
    "        # Average predictions and threshold\n",
    "        output = np.mean([pred6, pred7], axis=0)  \n",
    "        pred = threshold_binarize(output, threshold=t)\n",
    "\n",
    "        smooth=1.\n",
    "        y_true_f = K.flatten(np.array(val, dtype=np.float32))\n",
    "        y_pred_f = K.flatten(pred)\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        score = (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + smooth)\n",
    "\n",
    "        print(f\"Patient {i}: {score}\")\n",
    "        scores.append(float(score))\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = compute_validation_3dscore(0.5)\n",
    "print(\"Validation Mean 3D IoU:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze diff. thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# thresholds = [0.4, 0.5, 0.6, 0.7]\n",
    "# scores_3d = []\n",
    "# for t in tqdm(thresholds):\n",
    "#     scores_3d.append(np.mean(compute_validation_3dscore(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best_t = max(zip(thresholds, scores_3d), key=lambda x: x[1])\n",
    "# print(\"Best treshold:\", best_t[0], \" with score\", best_t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ax = sns.lineplot(x=thresholds, y=scores_3d)\n",
    "# ax = ax.set(xlabel='Treshold', ylabel=' 3D IoU')\n",
    "\n",
    "# print(scores_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on TEST and store\n",
    "Use the ensemble of Model B and Model C (i.e. model 6 and model 7 from development process) to predict and store the results (ensemble refered to as Model D in the report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for patient_name, img in tqdm(test_data, total=len(test_data)):\n",
    "    \n",
    "    # Extract patient number\n",
    "    patient_id = patient_name[0:9]\n",
    "    \n",
    "    # Predict with ensemble of Models B and C (i.e. use Model D)\n",
    "    pred6 = predict_patient_averaged(img, unet6, threshold=0.5) # Model B\n",
    "    pred7 = predict_patient_averaged(img, unet7, threshold=0.5) # Model C\n",
    "    output = np.mean([pred6, pred7], axis=0)\n",
    "    pred = np.array(threshold_binarize(output, threshold=0.5), dtype=np.float32)\n",
    "    \n",
    "    # Create folders\n",
    "    folder = f\"./predictions/model_{MODEL_NUMBER}_raw/prediction_test/patient_{patient_id}\"\n",
    "    os.makedirs(f\"{folder}\", exist_ok=True)\n",
    "    os.makedirs(f\"{folder}/raw\", exist_ok=True)\n",
    "    os.makedirs(f\"{folder}/thresh\", exist_ok=True)\n",
    "    \n",
    "    # Store pickle files of full 3D arrays\n",
    "    thresh_file = open(f\"{folder}/thresh_pickle_predict_patient_{patient_id}.pickle\", \"wb\")\n",
    "    raw_file = open(f\"{folder}/raw_pickle_predict_patient_{patient_id}.pickle\", \"wb\")\n",
    "    pkl.dump(pred, thresh_file)\n",
    "    pkl.dump(output, raw_file)\n",
    "    thresh_file.close()\n",
    "    raw_file.close()\n",
    "    \n",
    "    # Store individual layers as CSVs\n",
    "    for j in range(pred.shape[2]):\n",
    "        np.savetxt(f\"{folder}/raw/raw_predict_patient_{patient_id}_layer_{j}.csv.gz\", output[:,:,j], fmt=\"%1.6f\")\n",
    "        np.savetxt(f\"{folder}/thresh/thresh_predict_patient_{patient_id}_layer_{j}.csv.gz\", pred[:,:,j], fmt=\"%d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}